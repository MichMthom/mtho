
Part 1: Theoretical Understanding (40%)
1. Short Answer Questions

Q1: Explain the primary differences between TensorFlow and PyTorch. When would you choose one over the other?

Q2: Describe two use cases for Jupyter Notebooks in AI development.

Q3: How does spaCy enhance NLP tasks compared to basic Python string operations?

2. Comparative Analysis

Compare Scikit-learn and TensorFlow in terms of:

Target applications (e.g., classical ML vs. deep learning).

Ease of use for beginners.

Community support.

Part 2: Practical Implementation (50%)
Task 1: Classical ML with Scikit-learn

Dataset: Iris Species Dataset

Goal:

Preprocess the data (handle missing values, encode labels).

Train a decision tree classifier to predict iris species.

Evaluate using accuracy, precision, and recall.

Deliverable: Python script/Jupyter notebook with comments explaining each step.

Task 2: Deep Learning with TensorFlow/PyTorch

Dataset: MNIST Handwritten Digits

Goal:

Build a CNN model to classify handwritten digits.

Achieve >95% test accuracy.

Visualize the model’s predictions on 5 sample images.

Deliverable: Code with model architecture, training loop, and evaluation.

Task 3: NLP with spaCy

Text Data: User reviews from Amazon Product Reviews.

Goal:

Perform named entity recognition (NER) to extract product names and brands.

Analyze sentiment (positive/negative) using a rule-based approach.

Deliverable: Code snippet and output showing extracted entities and sentiment.

Part 3: Ethics & Optimization (10%)
1. Ethical Considerations

Identify potential biases in your MNIST or Amazon Reviews model. How could tools like TensorFlow Fairness Indicators or spaCy’s rule-based systems mitigate these biases?

2. Troubleshooting Challenge

Buggy Code: A provided TensorFlow script has errors (e.g., dimension mismatches, incorrect loss functions). Debug and fix the code.

Bonus Task (Extra 10%)

Deploy Your Model: Use Streamlit or Flask to create a web interface for your MNIST classifier. Submit a screenshot and a live demo link.

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

iris = load_iris()
X = iris.data
y = iris.target

# Encode labels
le = LabelEncoder()
y = le.fit_transform(y)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score

clf = DecisionTreeClassifier(random_state=42)
clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='weighted'))
print("Recall:", recall_score(y_test, y_pred, average='weighted'))

import tensorflow as tf
from tensorflow.keras.datasets import mnist

(X_train, y_train), (X_test, y_test) = mnist.load_data()

# Normalize pixel values
X_train = X_train.astype('float32') / 255
X_test = X_test.astype('float32') / 255

# Define CNN model
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Compile model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model.fit(X_train, y_train, epochs=5, batch_size=128, validation_data=(X_test, y_test))

test_loss, test_acc = model.evaluate(X_test, y_test)
print("Test accuracy:", test_acc)

import spacy

nlp = spacy.load("en_core_web_sm")

text = "I love the new iPhone from Apple!"
doc = nlp(text)

for ent in doc.ents:
    print(ent.text, ent.label_)

from spacy.util import minibatch, compounding

# Define sentiment analysis model
def sentiment_analysis(text):
    doc = nlp(text)
    sentiment = 0
    for token in doc:
        if token.pos_ == "ADJ":
            if token.text in ["good", "great", "excellent"]:
                sentiment += 1
            elif token.text in ["bad", "terrible", "awful"]:
                sentiment -= 1
    return sentiment

text = "I love the new iPhone from Apple!"
sentiment = sentiment_analysis(text)
print("Sentiment:", sentiment)

